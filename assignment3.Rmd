---
title: |
  <center> University of Edinburgh, School of Mathematics </center>
  <center> Incomplete Data Analysis, 2020/2021 </center>
  <center> Assignment 3 </center>
author: "Matilda Worlidge"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(rootdir="/Users/tilly/Documents/Incomplete Data Analysis/Assignment3")
```
All code included in this assignment is available in a GitHub repository at https://github.com/mworlidge/incomplete-data-analysis/blob/main/assignment3.Rmd. First I need to load all the necessary packages.
```{r install, message=FALSE, warning=FALSE}
require("mice")
require(JointAI)
require(devtools)
require(reshape2)
require(RColorBrewer)
require(ggplot2)
source_url("https://gist.githubusercontent.com/NErler/0d00375da460dd33839b98faeee2fdab/raw/c6f537ecf80eddcefd94992ec7926aa57d454536/propplot.R")
```

# Question 1
Considering the \texttt{nhanes} dataset, we can use the functions \texttt{dim} and \texttt{str} to explore the data and to see what we're working with.
```{r explore}
dim(nhanes)
str(nhanes)
```
This shows that we have 25 cases of 4 variables, \texttt{age}, \texttt{bmi}, \texttt{hyp} and \texttt{chl}.

### a)
The following code chunk shows that there are 13 complete cases and 12 incomplete cases. Therefore 48% of cases are incomplete.
```{r cc}
# number of complete cases
cc <- nrow(cc(nhanes))
# total number of cases
n <- nrow(nhanes) 
# percentage of missing cases
(n - cc)/n * 100
```
### b)
Now we can impute the data using the package \texttt{mice} using the default $\texttt{seed}=1$. In step 2 of the imputation (the \texttt{with()} function), we can predict \texttt{bmi} from \texttt{age}, \texttt{hyp} and \texttt{chl} by the normal linear regression model. 
```{r imp}
imps <- mice(nhanes, printFlag = FALSE, seed = 1)
fits <- with(imps, lm(bmi ~ age + hyp + chl))
```
Now we can proceed to step 3 and pool the analyses.
```{r step2}
ests <- pool(fits)
ests$pooled[, c(1, 3, 10)]
```
The proportions of variance due to the missing data from each parameter is denoted by the column $\lambda$ which is given by $\frac{B + \frac{B}{M}}{V^\top}$. Therefore we have $\lambda_{\text{age}} = 0.6864$, $\lambda_{\text{hyp}} = 0.3504$, $\lambda_{\text{chl}} = 0.3040$. The parameter that appears to be most affected by the nonresponse is \texttt{age} since it has the highest value for the proportions of variance due to the missing data.

### c)
We can now repeat this analysis with seeds 2, 3, 4, 5, and 6.
```{r seeds}
#using the default M=6 but changing the seed
ests2 <- pool(with(mice(nhanes, printFlag = FALSE, seed = 2), lm(bmi ~ age + hyp + chl)))
ests3 <- pool(with(mice(nhanes, printFlag = FALSE, seed = 3), lm(bmi ~ age + hyp + chl)))
ests4 <- pool(with(mice(nhanes, printFlag = FALSE, seed = 4), lm(bmi ~ age + hyp + chl)))
ests5 <- pool(with(mice(nhanes, printFlag = FALSE, seed = 5), lm(bmi ~ age + hyp + chl)))
ests6 <- pool(with(mice(nhanes, printFlag = FALSE, seed = 6), lm(bmi ~ age + hyp + chl)))

ests2$pooled[, c(1, 3, 10)]
ests3$pooled[, c(1, 3, 10)]
ests4$pooled[, c(1, 3, 10)]
ests5$pooled[, c(1, 3, 10)]
ests6$pooled[, c(1, 3, 10)]
```
From these results we can see that $\lambda$ changes significantly as the seed changes. The conclusions made for \texttt{seed}$=1$ are not the same as the conclusions made for the other seeds. When $\texttt{seed}=4$, the parameter that is most affected by the nonresponse is \texttt{chl}, and when $\texttt{seed}=5$, the parameter that is most affected by the nonresponse is \texttt{hyp}. For $\texttt{seed}=3$ and $\texttt{seed}=3$, the parameter \texttt{age} is still the parameter most affected by the nonresponse. When $\texttt{seed}=2$ the \texttt{Intercept} is the parameter most affeced by the nonresponse.

### d)
The conclusions from the previous question suggest that we should increase the number of datasets $M$. Therefore we repeat the analysis with $M=100$.
```{r m100}
#using M=100 and changing the seed
ests1m100 <- pool(with(mice(nhanes, M=100, printFlag = FALSE, seed = 1), 
                       lm(bmi ~ age + hyp + chl)))
ests2m100 <- pool(with(mice(nhanes, M=100, printFlag = FALSE, seed = 2), 
                       lm(bmi ~ age + hyp + chl)))
ests3m100 <- pool(with(mice(nhanes, M=100, printFlag = FALSE, seed = 3), 
                       lm(bmi ~ age + hyp + chl)))
ests4m100 <- pool(with(mice(nhanes, M=100, printFlag = FALSE, seed = 4), 
                       lm(bmi ~ age + hyp + chl)))
ests5m100 <- pool(with(mice(nhanes, M=100, printFlag = FALSE, seed = 5), 
                       lm(bmi ~ age + hyp + chl)))
ests6m100 <- pool(with(mice(nhanes, M=100, printFlag = FALSE, seed = 6), 
                       lm(bmi ~ age + hyp + chl)))

ests1m100$pooled[, c(1, 3, 10)]
ests2m100$pooled[, c(1, 3, 10)]
ests3m100$pooled[, c(1, 3, 10)]
ests4m100$pooled[, c(1, 3, 10)]
ests5m100$pooled[, c(1, 3, 10)]
ests6m100$pooled[, c(1, 3, 10)]

```

The (pooled) estimates should get more stable as M increases so we can be more confident in any one specific run. Therefore, I would prefer these analyses over $M=5$.

# Question 2
The file \texttt{dataex2} consists of 100 datasets that were generated in the following way 
\begin{equation*}
  y_i | x_i \overset{\text{iid}}{\sim} \text{N}(\beta_0 + \beta_1x_i, 1) \quad x_i \overset{\text{iid}}{\sim} \text{Unif}(-1,1) \quad \beta_0=1, \quad \beta_1=3
\end{equation*}
for $i=1,...,100$. Additionally some of the responses have been set to missing from the datasets under the MAR mechanism. 
```{r data}
# load the data 
load("dataex2.Rdata")
# store the number of datasets as n
n <- dim(dataex2)[1]
```

## Stochastic Regression Imputation 
```{r sri}
# initialize a counter
count <- 0
for (i in 1:n) {
  #impute values for the ith dataset using M=20
  imps_sri <- mice(dataex2[, , i], m = 20, method="norm.nob", printFlag = FALSE, seed = 1)
  fits_sri <- with(imps_sri, lm(Y ~ X)) #step 2
  ests_sri <- pool(fits_sri) # step 3
  summary_sri <- summary(ests_sri, conf.int = TRUE)
  if (summary_sri[2, c(7)] <= 3 & summary_sri[2, c(8)] >= 3) { 
    count <- count + 1 #add to the counter if the the value of beta1 is contained in the 
                       #confidence interval 
  }
}

ecp_sri <- count/n
ecp_sri
```
## Bootstrap version
```{r bootstrap}
# initialize a counter
count <- 0
for (i in 1:n) {
  #impute values for the ith dataset, using m=20
  imps_boot <- mice(dataex2[,,i], m = 20, method="norm.boot", printFlag = FALSE, seed = 1) 
  fits_sri <- with(imps_boot, lm(Y ~ X)) #step 2
  ests_boot <- pool(fits_sri) # step 3
  summary_boot <- summary(ests_boot, conf.int = TRUE)
  if (summary_boot[2, c(7)] <= 3 & summary_boot[2, c(8)] >= 3) {
    count = count + 1 #add to the counter if the true value of beta1 is contained in the 
                      #confidence interval 
  }
}

ecp_boot <- count/n
ecp_boot
```

Using stochastic regression imputation we get an empirical coverage probability of $88\%$. However when using the Bootstrap method we get an empirical coverage probability of $95\%$. The bootstrap method implements (normal linear) stochastic regression but takes parameter uncertainty into account. However the stochastic regression method implements (normal linear) stochastic regression for each copy $m$ of the dataset we have made $m=1,...,20$. Therefore parameter uncertainty is not taken into account since the same estimates are used for imputing all $20$ copies of the dataset. Therefore, the confidence intervals may be too narrow and affect the coverage of the intervals.
 
# Question 3
Given a dataset $\{y_i, x_{1i}, ..., x_{pi}\}$. We can consider a linear (in the coefficients) regression model 
\begin{equation*}
y_i = \beta_0 + \beta_1x_{1i} + ... + \beta_px_{pi} + \epsilon_i, \qquad \epsilon_i \sim \text{N}(0,\sigma^2).
\end{equation*}
For strategy (i), we first compute the predicted values from each fitted model in step 2,
\begin{equation*}
\hat{y}_i^{(m)} = \hat{\beta}_0^{(m)} + \hat{\beta}_1^{(m)}x_{1i} + ... + \hat{\beta}_p^{(m)}x_{pi},
\end{equation*}
where $\hat{\beta}_{j}^{(m)}$ is the estimate of $\beta_{j}$, $j = (0, ..., p)$, for the $m^{\text{th}}$ dataset. Then pool them according to Rubin's rule for point estimates,
\begin{align*}
\bar{y}_i &= \frac{1}{M} \sum_{i=1}^M \hat{y}_i^{(m)} \\
          &= \frac{1}{M} \hat{\beta}_0^{(m)} + \hat{\beta}_1^{(m)}x_{1i} + ... + \hat{\beta}_p^{(m)}x_{pi}\\
          &= \frac{1}{M} \sum_{i=1}^M \hat{\beta}_0^{(m)} + \frac{1}{M} \sum_{i=1}^M \hat{\beta}_1^{(m)}x_{1i} + ... + \frac{1}{M} \sum_{i=1}^M \hat{\beta}_p^{(m)}x_{pi} \\
          &= \bar{\beta}_0 + \bar{\beta}_1x_{1i} + ... + \bar{\beta}_px_{pi}
\end{align*}

Using strategy (ii), first we need to pool the regression coefficients from each fitted model in step 2 using Rubin's rule for point estimates,
\begin{align*}
\bar{\beta}_0 &= \frac{1}{M} \sum_{m=1}^M \hat{\beta}_0^{(m)} \\
\vdots \\
\bar{\beta}_p &= \frac{1}{M} \sum_{m=1}^M \hat{\beta}_p^{(m)}.
\end{align*}
Then we can compute the predicted values,
\begin{equation*}
\bar{y}_i = \bar{\beta}_0 + \bar{\beta}_1x_{1i} + ... + \bar{\beta}_px_{pi}
\end{equation*}
These two equations show that computing the predicted values from each fitted model in step 2 and then pooling them according to Rubin's rule for point estimates is the mathematically equivalent to pooling the regression coefficients from each fitted model in step 2 using Rubin's rule for point estimates and then computing the predicted values afterwards.

# Question 4
The model used to generate the data, which corresponds to our model of interest in step 2, was the following one:
\begin{align*}
  y_i &= \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} + \beta_3x_{1i}x_{2i} + \epsilon_i, \\
  x_{1i} \overset{\text{iid}}{\sim} &\text{N}(0,1), \qquad x_{2i} \overset{\text{iid}}{\sim} \text{N}(1.5,1), \qquad \epsilon_i \overset{\text{iid}}{\sim} \text{N}(0,1),
\end{align*}
for $i=1,...,1000, \beta_0 = 1.5, \beta_1 = 1, \beta_2 = 2, \beta_3 = 1.$ Missingness has been imposed on $y$ and $x_1$.
```{r data4}
load("dataex4.Rdata")
```
### a) Impute, then transform
By only imputing the $y$ and $x1$ variables in step 1, we can calculate estimates of $\beta_1$, $\beta_2$ and $\beta_3$, with the $95\%$ confidence intervals. In this approach the interaction variable is left outside the imputation process and calculated afterwards in the analysis model.
```{r Q4a}
imps1 <- mice(dataex4, m=50, seed=1, printFlag = FALSE)
fits1 <- with(imps1, lm(y ~ x1 + x2 + x1*x2))
ests1 <- pool(fits1)
summary(ests, conf.int = TRUE)[, c(1,2,3,7,8)]
```
This shows that the estimate of $\beta_2$ is approximately true. However the estimates of $\beta_1$ and $\beta_3$ are not very good and the true values do not lie in the $95\%$ confidence intervals.

### b) Passive imputation
Another method is passive imputation. We start by calculating the interaction variable $x_{3i} = x_{1i}x_{2i}$ in the incomplete data and appending it as a variable to the dataset. Then we will use passive imputation to impute the interaction variable.
```{r Q4b}
x1 <- dataex4$x1; x2 <- dataex4$x2; dataex4$x3 <- x1*x2
imp0 <- mice(dataex4, maxit=0)

meth <- imp0$method
meth["x3"] <- "~I(x1*x2)"

pred <- imp0$predictorMatrix
pred[c("x1", "x2"), "x3"] <- 0

visSeq <- imp0$visitSequence
visSeq

imps2 <- mice(dataex4, method = meth, predictorMatrix = pred, visitSequence = visSeq, 
              m = 50, seed = 1, printFlag = FALSE)

ests2 <- pool(with(imps2, lm(y ~ x1 + x2 + x1*x2)))

summary(ests2, conf.int=TRUE)[,c(1,2,3,7,8)]
```
The estimates have improved slightly for $\beta_1, \beta_2$ and $\beta_3$, however the true values of $\beta_1$ and $\beta_3$ still do not lie in the $95\%$ confidence intervals.

### c) Just another variable
Additionally, now that the interaction variable has been appended to the dataset, we can impute it just like another variable and use this variable for the interaction term in step 2.
```{r Q4c}
imps3 <- mice(dataex4, m = 50, seed = 1, printFlag = FALSE)
fits3 <- with(imps3, lm(y ~ x1 + x2 + x3))
ests3 <- pool(fits3)
summary(ests3, conf.int=TRUE)[, c(1,2,3,7,8)]
```
This method has improved the estimates greatly. All the estimates are approximately equal to the true values of the parameters and they all lie in the $95\%$ confidence intervals.

### d) 
The most obvious conceptual drawback of the \textit{just another variable} approach for imputing interactions is that because $x_3$ is the last column it is imputed using the $x_1$ and $x_2$ from the original dataset. 

# Question 5
The dataset \texttt{NHANES2.Rdata} is a subset of data from the \textit{National Health and Nutrition Examination Survey} (NHANES), where the goal is to assess the health and nutrition status of adults and children in the United States. The variables in the dataset are the following: 
\begin{itemize}
    \item \texttt{wgt}: weight in kg,
    \item \texttt{gender}: \texttt{male} vs \texttt{female},
    \item \texttt{bili}:  bilirubin concentration in mg/dL,
    \item \texttt{age}: in years,
    \item \texttt{chol}: total serum cholesterol in mg/dL,
    \item \texttt{HDL}: High-density lipoprotein cholesterol in mg/dL, 
    \item \texttt{hgt}: height in metres,
    \item \texttt{educ}: educational status; 5 ordered categories, 
    \item \texttt{race}: 5 unordered categories, 
    \item \texttt{SBP}: systolic blood pressure in mmHg,
    \item \texttt{hypten}: hypertensive; binary,
    \item \texttt{smoke}: smoking status; 3 ordered categories,
    \item \texttt{DM}: diabetes mellitus status; binary,
    \item \texttt{WC}: waist circumference in cm. 
\end{itemize}
The analysis of interest is the linear model:
\begin{equation} \label{lm}
    \text{wgt} = \beta_0 + \beta_1\text{gender} + \beta_2\text{age} + \beta_3\text{hgt} + \beta_4\text{WC} + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2).
\end{equation}
We can start by looking at the data, and by using the command \texttt{dim}, we see there are 500 rows (individuals), and 12 variables.
```{r set}
load("NHANES2.Rdata")
dim(NHANES2)
```
Using the command \texttt{str} we can inspect the nature of our variables and check they are coded correctly.
```{r str}
str(NHANES2)
```
Additionally, by using the \texttt{summary} command we can get an idea of the min/max/mean/quantiles of the observed data in each variable, as well as the number of missing values.
```{r summary}
summary(NHANES2)
```
I have used the \texttt{JointAI} package to inspect the missing data patterns. \texttt{JointAI} performs (Bayesian) multiple imputation and has useful visualisation functions.
```{r jointai, message=FALSE}
md_pattern(NHANES2, pattern = FALSE, color = c('#34111b', '#e30f41'))
```
Predictive mean matching is the default of \texttt{mice} for continuous variables. Since we want to use a normal linear regression model for imputing the missing values, we need to inspect whether the normality assumption is approximately met. The package \texttt{JointAI} allows us to visualise how the observed parts of the incomplete variables are distributed.
```{r plots}
par(mar = c(3, 3, 2, 1), mgp = c(2, 0.6, 0))
plot_all(NHANES2, breaks = 30, ncol = 4)
```
We are now ready to start the imputation procedure. I will start by doing a dry run of \texttt{mice()}, without any iterations, which will create the default versions of everything that needs to be specified. These default settings can then be adapted to this dataset.
```{r dry run}
imp0 <- mice(NHANES2, maxit = 0)
imp0
```
By assessing the plots, using a normal distribution for the \texttt{hgt} is not an unreasonable idea. Let us change the default imputation method from \texttt{pmm} to \texttt{norm} for the variable \texttt{hgt}.
```{r, include = TRUE, message = FALSE}
meth <- imp0$method
meth["hgt"] <- "norm"
meth
```
We do not want to impute negative values of height so we can use the function \texttt{post()} to specify functions that modify the imputed values. With the below syntax all imputed values of \texttt{hgt} that are outside the interval $(1.35, 1.95)$ will be set to those limiting values.

```{r, include = TRUE, message = FALSE}
post <- imp0$post
post["hgt"] <- "imp[[j]][,i] <- squeeze(imp[[j]][,i], c(1.35, 1.95))"
```
We can now begin the imputation.
```{r run}
imp <- mice(NHANES2, method = meth, maxit = 20, m = 30, seed = 1, printFlag = FALSE)
```
\texttt{mice()} does some pre-processing and removes incomplete variables that are not imputed but act as predictors in other imputation models, it also removes constant variables and variable that are collinear. Checking the \texttt{loggedEvents} contained in our object \texttt{imp} allows us to know if
\texttt{mice()} detected any problems during the imputation.
```{r logged events}
imp$loggedEvents
```
The mean and variance of the imputed values and variable are stored in the elements \texttt{chainMean} and \texttt{chainVar} of the \texttt{mids} object \texttt{imp}. To check that the \texttt{mice()} algorithm has converged, we can plot our object and visualize the trace plots. If the algorithm hasn't converged then there is no guarantee that the results obtained are correct.

```{r traceplots}
plot(imp, layout = c(4,4))
```
We can see that the iterative algorithm appears to have converged for all variables that were imputed. We can compare the distribution of the imputed values against the distribution of the observed values. For the continuous variables we can use the command \texttt{densityplot()}.
```{r density}
densityplot(imp)
```
We used $M=30$, and since the density of the observed values are plotted first (blue line), it is difficult to see. The plot which are most different are the ones for \texttt{SBP} and \texttt{hgt}. With regard to categorical variables, we can compare the proportion of values in each category. We can use \texttt{propplot}, implemented by Nicole Erler and available on her github.
```{r propplot, warning=FALSE}
propplot(imp)
```
This shows a large discrepancy between the observed and imputed data distributions for the educ variables. However there is only $0.2\%$ of data missing for this variable.

The imputation step was successful, so we can continue to the analysis of the imputed data. The model of interest is (\ref{lm}).
```{r fit lm}
fit <- with(imp, lm(wgt ~ gender + age + hgt + WC))
```

```{r chunk}
comp1 <- complete(imp, 1)
plot(fit$analyses[[1]]$fitted.values, residuals(fit$analyses[[1]]),
xlab = "Fitted values", ylab = "Residuals")
```
Doing a QQplot, we can see that nothing looks suspicious.
```{r qqplot}
qqnorm(rstandard(fit$analyses[[1]]), xlim = c(-4, 4), ylim = c(-6, 6))
qqline(rstandard(fit$analyses[[1]]), col = 2)
```
Now we can pool the results.
```{r pool}
pooled_ests <- pool(fit)
summary(pooled_ests, conf.int = TRUE)
pool.r.squared(pooled_ests, adjusted = TRUE)
```